{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:05.048042Z",
     "start_time": "2025-07-27T17:11:04.171808Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:05.088252Z",
     "start_time": "2025-07-27T17:11:05.068224Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv('toxic_comment.csv')",
   "id": "5ffa7e846eae0a37",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:05.390441Z",
     "start_time": "2025-07-27T17:11:05.371672Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "id": "f11aedcbb43d108a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              CommentId      VideoId  \\\n",
       "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
       "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
       "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
       "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
       "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
       "\n",
       "                                                Text  IsToxic  \n",
       "0  If only people would just take a step back and...    False  \n",
       "1  Law enforcement is not trained to shoot to app...     True  \n",
       "2  \\nDont you reckon them 'black lives matter' ba...     True  \n",
       "3  There are a very large number of people who do...    False  \n",
       "4  The Arab dude is absolutely right, he should h...    False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsToxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugg2KwwX0V8-aXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>If only people would just take a step back and...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugg2s5AzSPioEXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>Law enforcement is not trained to shoot to app...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugg3dWTOxryFfHgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>\\nDont you reckon them 'black lives matter' ba...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugg7Gd006w1MPngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>There are a very large number of people who do...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugg8FfTbbNF8IngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>The Arab dude is absolutely right, he should h...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:06.221183Z",
     "start_time": "2025-07-27T17:11:06.208681Z"
    }
   },
   "cell_type": "code",
   "source": "data.duplicated(subset=['CommentId', 'VideoId'], keep=False).sum()",
   "id": "cebb2c72f8828474",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:06.430688Z",
     "start_time": "2025-07-27T17:11:06.425125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    print('original data shape:', data.shape)\n",
    "\n",
    "    dropped_duplicated_data = data.drop_duplicates(subset=['CommentId', 'VideoId'], keep=False)\n",
    "    print('data shape after dropping duplicates:', dropped_duplicated_data.shape)\n",
    "\n",
    "    dropped_columns_data = dropped_duplicated_data.drop(columns=['CommentId', 'VideoId'], axis=1)\n",
    "    print('data shape after dropping columns:', dropped_columns_data.shape)\n",
    "\n",
    "    return dropped_columns_data"
   ],
   "id": "8822d719340c866b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:06.662458Z",
     "start_time": "2025-07-27T17:11:06.634639Z"
    }
   },
   "cell_type": "code",
   "source": "data = load_data('toxic_comment.csv')",
   "id": "7b35c5e258765e80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data shape: (1000, 4)\n",
      "data shape after dropping duplicates: (1000, 4)\n",
      "data shape after dropping columns: (1000, 2)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:06.769742Z",
     "start_time": "2025-07-27T17:11:06.759500Z"
    }
   },
   "cell_type": "code",
   "source": "# Data Preparation",
   "id": "72bb67349db5245a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:09.635943Z",
     "start_time": "2025-07-27T17:11:06.881884Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data.drop(columns=['IsToxic'], axis=1)\n",
    "y = data['IsToxic']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ],
   "id": "a67324b716d8227c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:09.685045Z",
     "start_time": "2025-07-27T17:11:09.670269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Training shape : X {x_train.shape}, y {y_train.shape}')\n",
    "print(f'Test shape : X {x_test.shape}, y {y_test.shape}')"
   ],
   "id": "6cc9ccaea958e9e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape : X (750, 1), y (750,)\n",
      "Test shape : X (250, 1), y (250,)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:09.749691Z",
     "start_time": "2025-07-27T17:11:09.730758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing Digits\n",
    "import re\n",
    "\n",
    "def remove_digits(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "x_train['Text'] = x_train['Text'].apply(remove_digits)"
   ],
   "id": "26a2d040ddfc23e4",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:09.828144Z",
     "start_time": "2025-07-27T17:11:09.801018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing punctuations\n",
    "import re\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ],
   "id": "bfe518b1557a5918",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.028888Z",
     "start_time": "2025-07-27T17:11:10.001095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize text\n",
    "def preprocess_text(data, column):\n",
    "    data[column] = data[column].str.lower()\n",
    "    data[column] = data[column].apply(remove_digits)\n",
    "    data[column] = data[column].apply(remove_punctuation)\n",
    "\n",
    "    return data"
   ],
   "id": "6d1b100569adb47a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.191543Z",
     "start_time": "2025-07-27T17:11:10.127771Z"
    }
   },
   "cell_type": "code",
   "source": "x_train_preprocessed = preprocess_text(x_train, 'Text')",
   "id": "9d0550e51cc27de4",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.230964Z",
     "start_time": "2025-07-27T17:11:10.222868Z"
    }
   },
   "cell_type": "code",
   "source": "# Vectorizing",
   "id": "dff4ba9502e339d1",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.291735Z",
     "start_time": "2025-07-27T17:11:10.284563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# One Hot Encoding\n",
    "def create_vocabs(sentences):\n",
    "    vocabs = []\n",
    "    for text in sentences:\n",
    "        for word in text.split():\n",
    "            vocabs.append(word)\n",
    "\n",
    "    return set(vocabs)"
   ],
   "id": "9d4686864743298e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.357789Z",
     "start_time": "2025-07-27T17:11:10.347811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus = [\n",
    "    'Hello World',\n",
    "    'Welcomee to Disney World',\n",
    "    'The flight is on delay'\n",
    "]"
   ],
   "id": "14d8ef2142fc2e68",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.416910Z",
     "start_time": "2025-07-27T17:11:10.412492Z"
    }
   },
   "cell_type": "code",
   "source": "# corpus = list(x_train_preprocessed['Text'])",
   "id": "ee749cc5d7bd3d26",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.461054Z",
     "start_time": "2025-07-27T17:11:10.455382Z"
    }
   },
   "cell_type": "code",
   "source": "vocabs = create_vocabs(corpus)",
   "id": "49325ce11642c839",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.503802Z",
     "start_time": "2025-07-27T17:11:10.497734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_to_idx = {word: idx for idx, word in enumerate(vocabs)}\n",
    "idx_to_word = {idx: word for idx, word in enumerate(vocabs)}"
   ],
   "id": "f9ce2b18d52388e5",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.564721Z",
     "start_time": "2025-07-27T17:11:10.556049Z"
    }
   },
   "cell_type": "code",
   "source": "word_to_idx",
   "id": "d6e2c2d4a5c1e22b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 0,\n",
       " 'The': 1,\n",
       " 'Hello': 2,\n",
       " 'Welcomee': 3,\n",
       " 'on': 4,\n",
       " 'to': 5,\n",
       " 'World': 6,\n",
       " 'Disney': 7,\n",
       " 'flight': 8,\n",
       " 'delay': 9}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.703481Z",
     "start_time": "2025-07-27T17:11:10.697579Z"
    }
   },
   "cell_type": "code",
   "source": "idx_to_word",
   "id": "1ea74015bd425ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'is',\n",
       " 1: 'The',\n",
       " 2: 'Hello',\n",
       " 3: 'Welcomee',\n",
       " 4: 'on',\n",
       " 5: 'to',\n",
       " 6: 'World',\n",
       " 7: 'Disney',\n",
       " 8: 'flight',\n",
       " 9: 'delay'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:10.808437Z",
     "start_time": "2025-07-27T17:11:10.803107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_of_vocabs = len(vocabs)\n",
    "number_of_sentences = len(corpus)\n",
    "\n",
    "word_presence_matrix = np.zeros(shape=(number_of_sentences, number_of_vocabs))\n",
    "word_presence_matrix"
   ],
   "id": "6562dd2b1d0d11ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:11.023598Z",
     "start_time": "2025-07-27T17:11:11.016346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for idx, sentence in enumerate(corpus):\n",
    "    for word in sentence.split():\n",
    "        word_index = word_to_idx[word]\n",
    "        word_presence_matrix[idx, word_index] = 1\n",
    "\n",
    "word_presence_matrix"
   ],
   "id": "397682e092f46e02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 1., 1., 1., 0., 0.],\n",
       "       [1., 1., 0., 0., 1., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:11:11.258407Z",
     "start_time": "2025-07-27T17:11:11.222926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "onehot_vector = pd.DataFrame(word_presence_matrix)\n",
    "onehot_vector.columns = list(word_to_idx.keys())\n",
    "onehot_vector.index = corpus\n",
    "onehot_vector"
   ],
   "id": "bb6d3db580635eeb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           is  The  Hello  Welcomee   on   to  World  Disney  \\\n",
       "Hello World               0.0  0.0    1.0       0.0  0.0  0.0    1.0     0.0   \n",
       "Welcomee to Disney World  0.0  0.0    0.0       1.0  0.0  1.0    1.0     1.0   \n",
       "The flight is on delay    1.0  1.0    0.0       0.0  1.0  0.0    0.0     0.0   \n",
       "\n",
       "                          flight  delay  \n",
       "Hello World                  0.0    0.0  \n",
       "Welcomee to Disney World     0.0    0.0  \n",
       "The flight is on delay       1.0    1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>The</th>\n",
       "      <th>Hello</th>\n",
       "      <th>Welcomee</th>\n",
       "      <th>on</th>\n",
       "      <th>to</th>\n",
       "      <th>World</th>\n",
       "      <th>Disney</th>\n",
       "      <th>flight</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hello World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welcomee to Disney World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The flight is on delay</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:14:20.303656Z",
     "start_time": "2025-07-27T17:14:20.298454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OneHotVectorizer:\n",
    "\n",
    "    corpus = []\n",
    "    vocabularies = set()\n",
    "    word_to_idx = {}\n",
    "    idx_to_word = {}\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        self.generate_vocabulary()\n",
    "        self.word_to_idx = {word: idx for idx, word in enumerate(self.vocabularies)}\n",
    "        self.idx_to_word = {idx: word for idx, word in enumerate(self.vocabularies)}\n",
    "\n",
    "    def get_vocab(self) :\n",
    "        return self.vocabularies\n",
    "\n",
    "    def get_mapping(self) :\n",
    "        return self.word_to_idx, self.idx_to_word\n",
    "\n",
    "    def generate_vocabulary(self):\n",
    "        self.vocabularies = set()\n",
    "        for sentence in self.corpus:\n",
    "            word_split = sentence.split()\n",
    "            for word in word_split:\n",
    "                self.vocabularies.add(word)\n",
    "\n",
    "    def transform(self, text):\n",
    "        number_of_sentences = number_of_sentences\n",
    "        number_of_vocabs = len(self.vocabularies)\n",
    "        text_features = np.zeros(shape=(number_of_sentences, number_of_vocabs))\n",
    "        for idx, sentence in enumerate(text):\n",
    "            for word in sentence.split():\n",
    "                if word not in self.word_to_idx.keys():\n",
    "                    continue\n",
    "\n",
    "                word_index = self.word_to_idx[word]\n",
    "                text_features[idx, word_index] = 1\n",
    "\n",
    "        return text_features"
   ],
   "id": "465e806ff8120661",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:14:21.809649Z",
     "start_time": "2025-07-27T17:14:21.805504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "onehot_vectorizer = OneHotVectorizer()\n",
    "onehot_vectorizer.fit(corpus)\n",
    "onehot_text_features = onehot_vectorizer.transform(corpus)"
   ],
   "id": "c4ccf6156f371779",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:14:23.513151Z",
     "start_time": "2025-07-27T17:14:23.502350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "onehot_df = pd.DataFrame(onehot_text_features)\n",
    "onehot_df.columns = list(onehot_vectorizer.get_mapping()[0].keys())\n",
    "onehot_df.index = corpus\n",
    "onehot_df"
   ],
   "id": "f0b49cce8047c3a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                           is  The  Hello  Welcomee   on   to  World  Disney  \\\n",
       "Hello World               0.0  0.0    1.0       0.0  0.0  0.0    1.0     0.0   \n",
       "Welcomee to Disney World  0.0  0.0    0.0       1.0  0.0  1.0    1.0     1.0   \n",
       "The flight is on delay    1.0  1.0    0.0       0.0  1.0  0.0    0.0     0.0   \n",
       "\n",
       "                          flight  delay  \n",
       "Hello World                  0.0    0.0  \n",
       "Welcomee to Disney World     0.0    0.0  \n",
       "The flight is on delay       1.0    1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>The</th>\n",
       "      <th>Hello</th>\n",
       "      <th>Welcomee</th>\n",
       "      <th>on</th>\n",
       "      <th>to</th>\n",
       "      <th>World</th>\n",
       "      <th>Disney</th>\n",
       "      <th>flight</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hello World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welcomee to Disney World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The flight is on delay</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:20:16.594892Z",
     "start_time": "2025-07-27T17:20:16.590112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CountVectorizer:\n",
    "\n",
    "    corpus = []\n",
    "    vocabularies = set()\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        self.generate_vocabularies()\n",
    "        self.word_to_idx = {word: idx for idx, word in enumerate(self.vocabularies)}\n",
    "        self.idx_to_word = {idx: word for idx, word in enumerate(self.vocabularies)}\n",
    "\n",
    "    def get_vocab(self) :\n",
    "        return self.vocabularies\n",
    "\n",
    "    def get_mapping(self) :\n",
    "        return self.word_to_idx, self.idx_to_word\n",
    "\n",
    "    def generate_vocabularies(self):\n",
    "        self.vocabularies = set()\n",
    "        for sentence in self.corpus:\n",
    "            word_split = sentence.split()\n",
    "            for word in word_split:\n",
    "                self.vocabularies.add(word)\n",
    "\n",
    "    def transform(self, text):\n",
    "        number_of_sentences = len(text)\n",
    "        number_of_vocabs = len(self.vocabularies)\n",
    "        text_features = np.zeros(shape=(number_of_sentences, number_of_vocabs))\n",
    "\n",
    "        for idx, sentence in enumerate(text):\n",
    "            for word in sentence.split():\n",
    "                if word not in self.word_to_idx.keys():\n",
    "                    continue\n",
    "\n",
    "                word_index = self.word_to_idx[word]\n",
    "                text_features[idx, word_index] += 1\n",
    "\n",
    "        return text_features"
   ],
   "id": "f1fd5abdaa1bde63",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:20:18.896936Z",
     "start_time": "2025-07-27T17:20:18.893716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus_bow = [\n",
    "    'Hello World',\n",
    "    'Welcomee to Disney World',\n",
    "    'The flight is on delay',\n",
    "    'The flight because the runaway is being used for another flight departure'\n",
    "]"
   ],
   "id": "f44f206a3759dfc4",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:20:20.643957Z",
     "start_time": "2025-07-27T17:20:20.637235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(corpus_bow)\n",
    "count_vectorizer_features = count_vectorizer.transform(corpus_bow)\n",
    "\n",
    "count_vectorizer_features"
   ],
   "id": "e06a25df648e4d04",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 0.],\n",
       "       [1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 1.],\n",
       "       [1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 2., 1.,\n",
       "        1., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T17:21:00.063190Z",
     "start_time": "2025-07-27T17:21:00.048624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "onehot_df = pd.DataFrame(count_vectorizer_features)\n",
    "onehot_df.columns = list(count_vectorizer.get_mapping()[0].keys())\n",
    "onehot_df.index = corpus_bow\n",
    "onehot_df"
   ],
   "id": "5d600bc7c311e3f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                     is  because  The  \\\n",
       "Hello World                                         0.0      0.0  0.0   \n",
       "Welcomee to Disney World                            0.0      0.0  0.0   \n",
       "The flight is on delay                              1.0      0.0  1.0   \n",
       "The flight because the runaway is being used fo...  1.0      1.0  1.0   \n",
       "\n",
       "                                                    departure  Hello  \\\n",
       "Hello World                                               0.0    1.0   \n",
       "Welcomee to Disney World                                  0.0    0.0   \n",
       "The flight is on delay                                    0.0    0.0   \n",
       "The flight because the runaway is being used fo...        1.0    0.0   \n",
       "\n",
       "                                                    Welcomee   on   to  \\\n",
       "Hello World                                              0.0  0.0  0.0   \n",
       "Welcomee to Disney World                                 1.0  0.0  1.0   \n",
       "The flight is on delay                                   0.0  1.0  0.0   \n",
       "The flight because the runaway is being used fo...       0.0  0.0  0.0   \n",
       "\n",
       "                                                    runaway  being  World  \\\n",
       "Hello World                                             0.0    0.0    1.0   \n",
       "Welcomee to Disney World                                0.0    0.0    1.0   \n",
       "The flight is on delay                                  0.0    0.0    0.0   \n",
       "The flight because the runaway is being used fo...      1.0    1.0    0.0   \n",
       "\n",
       "                                                    another  Disney  the  \\\n",
       "Hello World                                             0.0     0.0  0.0   \n",
       "Welcomee to Disney World                                0.0     1.0  0.0   \n",
       "The flight is on delay                                  0.0     0.0  0.0   \n",
       "The flight because the runaway is being used fo...      1.0     0.0  1.0   \n",
       "\n",
       "                                                    flight  for  used  delay  \n",
       "Hello World                                            0.0  0.0   0.0    0.0  \n",
       "Welcomee to Disney World                               0.0  0.0   0.0    0.0  \n",
       "The flight is on delay                                 1.0  0.0   0.0    1.0  \n",
       "The flight because the runaway is being used fo...     2.0  1.0   1.0    0.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is</th>\n",
       "      <th>because</th>\n",
       "      <th>The</th>\n",
       "      <th>departure</th>\n",
       "      <th>Hello</th>\n",
       "      <th>Welcomee</th>\n",
       "      <th>on</th>\n",
       "      <th>to</th>\n",
       "      <th>runaway</th>\n",
       "      <th>being</th>\n",
       "      <th>World</th>\n",
       "      <th>another</th>\n",
       "      <th>Disney</th>\n",
       "      <th>the</th>\n",
       "      <th>flight</th>\n",
       "      <th>for</th>\n",
       "      <th>used</th>\n",
       "      <th>delay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hello World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welcomee to Disney World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The flight is on delay</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The flight because the runaway is being used for another flight departure</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bb4d444aceca41a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
