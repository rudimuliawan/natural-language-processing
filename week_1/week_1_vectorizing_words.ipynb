{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:46.364169Z",
     "start_time": "2025-07-27T11:48:46.362019Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 167
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:46.456324Z",
     "start_time": "2025-07-27T11:48:46.440015Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv('toxic_comment.csv')",
   "id": "5ffa7e846eae0a37",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:46.518992Z",
     "start_time": "2025-07-27T11:48:46.513920Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "id": "f11aedcbb43d108a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              CommentId      VideoId  \\\n",
       "0  Ugg2KwwX0V8-aXgCoAEC  04kJtp6pVXI   \n",
       "1  Ugg2s5AzSPioEXgCoAEC  04kJtp6pVXI   \n",
       "2  Ugg3dWTOxryFfHgCoAEC  04kJtp6pVXI   \n",
       "3  Ugg7Gd006w1MPngCoAEC  04kJtp6pVXI   \n",
       "4  Ugg8FfTbbNF8IngCoAEC  04kJtp6pVXI   \n",
       "\n",
       "                                                Text  IsToxic  \n",
       "0  If only people would just take a step back and...    False  \n",
       "1  Law enforcement is not trained to shoot to app...     True  \n",
       "2  \\nDont you reckon them 'black lives matter' ba...     True  \n",
       "3  There are a very large number of people who do...    False  \n",
       "4  The Arab dude is absolutely right, he should h...    False  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CommentId</th>\n",
       "      <th>VideoId</th>\n",
       "      <th>Text</th>\n",
       "      <th>IsToxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugg2KwwX0V8-aXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>If only people would just take a step back and...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ugg2s5AzSPioEXgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>Law enforcement is not trained to shoot to app...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ugg3dWTOxryFfHgCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>\\nDont you reckon them 'black lives matter' ba...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ugg7Gd006w1MPngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>There are a very large number of people who do...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ugg8FfTbbNF8IngCoAEC</td>\n",
       "      <td>04kJtp6pVXI</td>\n",
       "      <td>The Arab dude is absolutely right, he should h...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:46.632155Z",
     "start_time": "2025-07-27T11:48:46.628149Z"
    }
   },
   "cell_type": "code",
   "source": "data.duplicated(subset=['CommentId', 'VideoId'], keep=False).sum()",
   "id": "cebb2c72f8828474",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:46.704584Z",
     "start_time": "2025-07-27T11:48:46.702245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    print('original data shape:', data.shape)\n",
    "\n",
    "    dropped_duplicated_data = data.drop_duplicates(subset=['CommentId', 'VideoId'], keep=False)\n",
    "    print('data shape after dropping duplicates:', dropped_duplicated_data.shape)\n",
    "\n",
    "    dropped_columns_data = dropped_duplicated_data.drop(columns=['CommentId', 'VideoId'], axis=1)\n",
    "    print('data shape after dropping columns:', dropped_columns_data.shape)\n",
    "\n",
    "    return dropped_columns_data"
   ],
   "id": "8822d719340c866b",
   "outputs": [],
   "execution_count": 171
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:46.834884Z",
     "start_time": "2025-07-27T11:48:46.827243Z"
    }
   },
   "cell_type": "code",
   "source": "data = load_data('toxic_comment.csv')",
   "id": "7b35c5e258765e80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data shape: (1000, 4)\n",
      "data shape after dropping duplicates: (1000, 4)\n",
      "data shape after dropping columns: (1000, 2)\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:46.916982Z",
     "start_time": "2025-07-27T11:48:46.915222Z"
    }
   },
   "cell_type": "code",
   "source": "# Data Preparation",
   "id": "72bb67349db5245a",
   "outputs": [],
   "execution_count": 173
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:46.979523Z",
     "start_time": "2025-07-27T11:48:46.975101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = data.drop(columns=['IsToxic'], axis=1)\n",
    "y = data['IsToxic']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ],
   "id": "a67324b716d8227c",
   "outputs": [],
   "execution_count": 174
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.030488Z",
     "start_time": "2025-07-27T11:48:47.028342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Training shape : X {x_train.shape}, y {y_train.shape}')\n",
    "print(f'Test shape : X {x_test.shape}, y {y_test.shape}')"
   ],
   "id": "6cc9ccaea958e9e7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape : X (750, 1), y (750,)\n",
      "Test shape : X (250, 1), y (250,)\n"
     ]
    }
   ],
   "execution_count": 175
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.080528Z",
     "start_time": "2025-07-27T11:48:47.076566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing Digits\n",
    "import re\n",
    "\n",
    "def remove_digits(text):\n",
    "    return re.sub(r'\\d+', '', text)\n",
    "\n",
    "x_train['Text'] = x_train['Text'].apply(remove_digits)"
   ],
   "id": "26a2d040ddfc23e4",
   "outputs": [],
   "execution_count": 176
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.146371Z",
     "start_time": "2025-07-27T11:48:47.144081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Removing punctuations\n",
    "import re\n",
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', string.punctuation))"
   ],
   "id": "bfe518b1557a5918",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.191740Z",
     "start_time": "2025-07-27T11:48:47.189567Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Tokenize text\n",
    "def preprocess_text(data, column):\n",
    "    data[column] = data[column].str.lower()\n",
    "    data[column] = data[column].apply(remove_digits)\n",
    "    data[column] = data[column].apply(remove_punctuation)\n",
    "\n",
    "    return data"
   ],
   "id": "6d1b100569adb47a",
   "outputs": [],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.261447Z",
     "start_time": "2025-07-27T11:48:47.248429Z"
    }
   },
   "cell_type": "code",
   "source": "x_train_preprocessed = preprocess_text(x_train, 'Text')",
   "id": "9d0550e51cc27de4",
   "outputs": [],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.299911Z",
     "start_time": "2025-07-27T11:48:47.298393Z"
    }
   },
   "cell_type": "code",
   "source": "# Vectorizing",
   "id": "dff4ba9502e339d1",
   "outputs": [],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.372018Z",
     "start_time": "2025-07-27T11:48:47.369882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# One Hot Encoding\n",
    "def create_vocabs(sentences):\n",
    "    vocabs = []\n",
    "    for text in sentences:\n",
    "        for word in text.split():\n",
    "            vocabs.append(word)\n",
    "\n",
    "    return set(vocabs)"
   ],
   "id": "9d4686864743298e",
   "outputs": [],
   "execution_count": 181
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.421114Z",
     "start_time": "2025-07-27T11:48:47.419486Z"
    }
   },
   "cell_type": "code",
   "source": [
    "corpus = [\n",
    "    'Hello World',\n",
    "    'Welcomee to Disney World',\n",
    "    'The flight is on delay'\n",
    "]"
   ],
   "id": "14d8ef2142fc2e68",
   "outputs": [],
   "execution_count": 182
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.479178Z",
     "start_time": "2025-07-27T11:48:47.477425Z"
    }
   },
   "cell_type": "code",
   "source": "# corpus = list(x_train_preprocessed['Text'])",
   "id": "ee749cc5d7bd3d26",
   "outputs": [],
   "execution_count": 183
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.524406Z",
     "start_time": "2025-07-27T11:48:47.522415Z"
    }
   },
   "cell_type": "code",
   "source": "vocabs = create_vocabs(corpus)",
   "id": "49325ce11642c839",
   "outputs": [],
   "execution_count": 184
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.564331Z",
     "start_time": "2025-07-27T11:48:47.562487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "word_to_idx = {word: idx for idx, word in enumerate(vocabs)}\n",
    "idx_to_word = {idx: word for idx, word in enumerate(vocabs)}"
   ],
   "id": "f9ce2b18d52388e5",
   "outputs": [],
   "execution_count": 185
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.630318Z",
     "start_time": "2025-07-27T11:48:47.626675Z"
    }
   },
   "cell_type": "code",
   "source": "word_to_idx",
   "id": "d6e2c2d4a5c1e22b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flight': 0,\n",
       " 'World': 1,\n",
       " 'delay': 2,\n",
       " 'The': 3,\n",
       " 'to': 4,\n",
       " 'Disney': 5,\n",
       " 'on': 6,\n",
       " 'Welcomee': 7,\n",
       " 'Hello': 8,\n",
       " 'is': 9}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.664761Z",
     "start_time": "2025-07-27T11:48:47.661067Z"
    }
   },
   "cell_type": "code",
   "source": "idx_to_word",
   "id": "1ea74015bd425ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'flight',\n",
       " 1: 'World',\n",
       " 2: 'delay',\n",
       " 3: 'The',\n",
       " 4: 'to',\n",
       " 5: 'Disney',\n",
       " 6: 'on',\n",
       " 7: 'Welcomee',\n",
       " 8: 'Hello',\n",
       " 9: 'is'}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.738431Z",
     "start_time": "2025-07-27T11:48:47.735674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "number_of_vocabs = len(vocabs)\n",
    "number_of_sentences = len(corpus)\n",
    "\n",
    "word_presence_matrix = np.zeros(shape=(number_of_sentences, number_of_vocabs))\n",
    "word_presence_matrix"
   ],
   "id": "6562dd2b1d0d11ee",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 188
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.867531Z",
     "start_time": "2025-07-27T11:48:47.864256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for idx, sentence in enumerate(corpus):\n",
    "    for word in sentence.split():\n",
    "        word_index = word_to_idx[word]\n",
    "        word_presence_matrix[idx, word_index] = 1\n",
    "\n",
    "word_presence_matrix"
   ],
   "id": "397682e092f46e02",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
       "       [1., 0., 1., 1., 0., 0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 189
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:47.973485Z",
     "start_time": "2025-07-27T11:48:47.964126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "onehot_vector = pd.DataFrame(word_presence_matrix)\n",
    "onehot_vector.columns = list(word_to_idx.keys())\n",
    "onehot_vector.index = corpus\n",
    "onehot_vector"
   ],
   "id": "bb6d3db580635eeb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          flight  World  delay  The   to  Disney   on  \\\n",
       "Hello World                  0.0    1.0    0.0  0.0  0.0     0.0  0.0   \n",
       "Welcomee to Disney World     0.0    1.0    0.0  0.0  1.0     1.0  0.0   \n",
       "The flight is on delay       1.0    0.0    1.0  1.0  0.0     0.0  1.0   \n",
       "\n",
       "                          Welcomee  Hello   is  \n",
       "Hello World                    0.0    1.0  0.0  \n",
       "Welcomee to Disney World       1.0    0.0  0.0  \n",
       "The flight is on delay         0.0    0.0  1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight</th>\n",
       "      <th>World</th>\n",
       "      <th>delay</th>\n",
       "      <th>The</th>\n",
       "      <th>to</th>\n",
       "      <th>Disney</th>\n",
       "      <th>on</th>\n",
       "      <th>Welcomee</th>\n",
       "      <th>Hello</th>\n",
       "      <th>is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hello World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welcomee to Disney World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The flight is on delay</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 190
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:48.088900Z",
     "start_time": "2025-07-27T11:48:48.084673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class OneHotVectorizer:\n",
    "\n",
    "    corpus = []\n",
    "    vocabularies = set()\n",
    "    word_to_idx = {}\n",
    "    idx_to_word = {}\n",
    "\n",
    "    def fit(self, corpus):\n",
    "        self.corpus = corpus\n",
    "        self.generate_vocabulary()\n",
    "        self.word_to_idx = {word: idx for idx, word in enumerate(self.vocabularies)}\n",
    "        self.idx_to_word = {idx: word for idx, word in enumerate(self.vocabularies)}\n",
    "\n",
    "    def get_vocab(self) :\n",
    "        return self.vocabularies\n",
    "\n",
    "    def get_mapping(self) :\n",
    "        return self.word_to_idx, self.idx_to_word\n",
    "\n",
    "    def generate_vocabulary(self):\n",
    "        self.vocabularies = set()\n",
    "        for sentence in corpus:\n",
    "            word_split = sentence.split()\n",
    "            for word in word_split:\n",
    "                self.vocabularies.add(word)\n",
    "\n",
    "    def transform(self, text):\n",
    "        text_features = np.zeros(shape=(number_of_sentences, number_of_vocabs))\n",
    "        for idx, sentence in enumerate(text):\n",
    "            for word in sentence.split():\n",
    "                if word not in self.word_to_idx.keys():\n",
    "                    continue\n",
    "\n",
    "                word_index = self.word_to_idx[word]\n",
    "                text_features[idx, word_index] = 1\n",
    "\n",
    "        return text_features"
   ],
   "id": "465e806ff8120661",
   "outputs": [],
   "execution_count": 191
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:48.171963Z",
     "start_time": "2025-07-27T11:48:48.169336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "onehot_vectorizer = OneHotVectorizer()\n",
    "onehot_vectorizer.fit(corpus)\n",
    "onehot_text_features = onehot_vectorizer.transform(corpus)"
   ],
   "id": "c4ccf6156f371779",
   "outputs": [],
   "execution_count": 192
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-27T11:48:50.722200Z",
     "start_time": "2025-07-27T11:48:50.711804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "onehot_df = pd.DataFrame(onehot_text_features)\n",
    "onehot_df.columns = list(onehot_vectorizer.get_mapping()[0].keys())\n",
    "onehot_df.index = corpus\n",
    "onehot_df"
   ],
   "id": "f0b49cce8047c3a4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          flight  World  delay  The   to  Disney   on  \\\n",
       "Hello World                  0.0    1.0    0.0  0.0  0.0     0.0  0.0   \n",
       "Welcomee to Disney World     0.0    1.0    0.0  0.0  1.0     1.0  0.0   \n",
       "The flight is on delay       1.0    0.0    1.0  1.0  0.0     0.0  1.0   \n",
       "\n",
       "                          Welcomee  Hello   is  \n",
       "Hello World                    0.0    1.0  0.0  \n",
       "Welcomee to Disney World       1.0    0.0  0.0  \n",
       "The flight is on delay         0.0    0.0  1.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight</th>\n",
       "      <th>World</th>\n",
       "      <th>delay</th>\n",
       "      <th>The</th>\n",
       "      <th>to</th>\n",
       "      <th>Disney</th>\n",
       "      <th>on</th>\n",
       "      <th>Welcomee</th>\n",
       "      <th>Hello</th>\n",
       "      <th>is</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hello World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Welcomee to Disney World</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The flight is on delay</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 193
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
